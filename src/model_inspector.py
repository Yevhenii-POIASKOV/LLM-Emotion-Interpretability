import torch
import numpy as np
import os
from datetime import datetime
from data_loader import get_model, get_emotional_batches

def run_model_inspection(base_path: str = "LLM-Emotion-Interpretability/data/activations") -> None:
    # --- 1. –ë–ê–ó–û–í–ê –ü–ê–ü–ö–ê ---
    project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    base_path = os.path.join(project_root, "data", "activations")  # –¢—É—Ç –±—É–¥—É—Ç—å –∑–±–∏—Ä–∞—Ç–∏—Å—è –≤—Å—ñ –∑–∞–ø—É—Å–∫–∏

    # --- 2. –ì–ï–ù–ï–†–£–Ñ–ú–û –ù–ê–ó–í–£ –î–õ–Ø –ù–û–í–û–ì–û –ó–ê–ü–£–°–ö–£ ---
    # –§–æ—Ä–º–∞—Ç: run_–†–†–†–†–ú–ú–î–î_–ì–ì–•–• (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, run_20240520_1430)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M")
    run_folder_name = f"run_{timestamp}"

    # –ü–æ–≤–Ω–∏–π —à–ª—è—Ö –¥–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ—ó –ø–∞–ø–∫–∏ —Ü—å–æ–≥–æ –∑–∞–ø—É—Å–∫—É

    final_output_path = os.path.join(base_path, run_folder_name)

    # --- –ö–û–ù–§–Ü–ì–£–†–ê–¶–Ü–Ø –ú–û–î–ï–õ–Ü ---
    model = get_model()

    blocks_to_save = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]

    # –°—Ç–≤–æ—Ä—é—î–º–æ –Ω–æ–≤—É –ø–∞–ø–∫—É
    if not os.path.exists(final_output_path):
        os.makedirs(final_output_path)
        print(f"üìÇ –°—Ç–≤–æ—Ä–µ–Ω–æ –Ω–æ–≤—É –ø–∞–ø–∫—É –¥–ª—è —Ü—å–æ–≥–æ –∑–∞–ø—É—Å–∫—É: {final_output_path}")

    # –°—Ö–æ–≤–∏—â–∞ –∞–∫—Ç–∏–≤–∞—Ü—ñ–π
    activations_db = {b: [] for b in blocks_to_save}
    all_labels = []

    print(f"üìä –ü–æ—á–∏–Ω–∞—î–º–æ –∑–±—ñ—Ä –¥–∞–Ω–∏—Ö...")

    for batch in get_emotional_batches(batch_size=16, model=model):
        
        names_filter = [f"blocks.{b}.mlp.hook_post" for b in blocks_to_save]

        with torch.no_grad():

            _, cache = model.run_with_cache(batch.tokens, names_filter=names_filter)

        all_labels.append(batch.labels.cpu().numpy())

        for b in blocks_to_save:

            # –í–∏—Ç—è–≥—É—î–º–æ –∞–∫—Ç–∏–≤–∞—Ü—ñ—ó –æ—Å—Ç–∞–Ω–Ω—å–æ–≥–æ —Ç–æ–∫–µ–Ω–∞

            layer_acts = cache[f"blocks.{b}.mlp.hook_post"][:, -1, :].cpu().numpy()

            activations_db[b].append(layer_acts)

    print("\nüíæ –ó–∞–ø–∏—Å —Ñ–∞–π–ª—ñ–≤ —É –Ω–æ–≤—É –ø–∞–ø–∫—É...")

    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –∞–∫—Ç–∏–≤–∞—Ü—ñ—ó
    for b in blocks_to_save:
        if activations_db[b]:
            final_matrix = np.concatenate(activations_db[b], axis=0)
            file_path = os.path.join(final_output_path, f"mlp_layer_{b}.npy")
            np.save(file_path, final_matrix)
            print(f"‚úÖ –ó–±–µ—Ä–µ–∂–µ–Ω–æ: {f'mlp_layer_{b}.npy'}")
        else:
            print(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –¥–ª—è —à–∞—Ä—É {b}: –Ω–µ –∑—ñ–±—Ä–∞–Ω–æ –∂–æ–¥–Ω–∏—Ö –∞–∫—Ç–∏–≤–∞—Ü—ñ–π.")
        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –º—ñ—Ç–∫–∏
        if all_labels:
            np.save(os.path.join(final_output_path, "labels.npy"), np.concatenate(all_labels))
            print("‚úÖ –ó–±–µ—Ä–µ–∂–µ–Ω–æ: labels.npy")
        else:
            print("‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –º—ñ—Ç–æ–∫: –Ω–µ –∑—ñ–±—Ä–∞–Ω–æ –∂–æ–¥–Ω–æ—ó –º—ñ—Ç–∫–∏.")

    print(f"\n‚ú® –ì–æ—Ç–æ–≤–æ! –£—Å—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ —Ü—å–æ–≥–æ —Å–µ–∞–Ω—Å—É –∑–±–µ—Ä–µ–∂–µ–Ω–æ —Ç—É—Ç:\n{final_output_path}")

if __name__ == "__main__":
    run_model_inspection()